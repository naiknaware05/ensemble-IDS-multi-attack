{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "All_Classifiers",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1HLTe35BhV3u1GkEykbGxPV71as3t214F",
      "authorship_tag": "ABX9TyMfVPVXUTskHTVGrzKWze0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/assa-be-project/ensemble-IDS-multi-attack/blob/master/All_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlJMPXwgy5NU",
        "colab_type": "code",
        "outputId": "0536c397-103a-4a98-a6c4-b90fdad51bd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "def xgboostClassifier(Feature_train, y_train, Feature_test):\n",
        "  model = XGBClassifier(max_depth=6, colsample_bytree=0.9, colsample_bynode=0.9, colsample_bylevel=0.9, learning_rate=0.15, \n",
        "                          min_child_weight = 1 , n_estimators=100, objective='multi:softprob')\n",
        "  model.fit(Feature_train, y_train)\n",
        "  y_pred = model.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        "def baggingClassifier_DT(Feature_train, y_train, Feature_test):\n",
        "  bag_clf = BaggingClassifier(DecisionTreeClassifier(max_depth = 6, criterion='gini', max_features=15, random_state=17),\n",
        "                            n_estimators = 150, \n",
        "                            bootstrap=True, oob_score=True)\n",
        "  bag_clf.fit(Feature_train, y_train)\n",
        "  y_pred = bag_clf.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        "def adaboostClassifier(Feature_train, y_train, Feature_test):\n",
        "  ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=6,criterion='gini', max_features=17, random_state=17),\n",
        "                             algorithm=\"SAMME.R\",n_estimators=100, learning_rate= 1.5)\n",
        "  ada_clf.fit(Feature_train, y_train)\n",
        "  y_pred_ada = ada_clf.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        "def randomForestCLassifier(Feature_train, y_train, Feature_test):\n",
        "  clf = RandomForestClassifier(n_estimators=1000)\n",
        "  clf = clf.fit(Feature_train, y_train)\n",
        "  y_pred = clf.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        "def extraTreesClassifier(Feature_train, y_train, Feature_test):\n",
        "  clf = ExtraTreesClassifier(n_estimators=1000)\n",
        "  clf = clf.fit(Feature_train, y_train)\n",
        "  y_pred = clf.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        "def stackingClassifier(Feature_train, y_train, Feature_test):\n",
        "  layer_one_estimators = [('rf_1', DecisionTreeClassifier(max_depth=6, max_features=15)), ('knn_1', KNeighborsClassifier(n_neighbors=35))]\n",
        "  \n",
        "  layer_two_estimators = [('dt_2', DecisionTreeClassifier(max_depth=6, max_features=15)),('rf_2', svm.SVC())]\n",
        "  \n",
        "  layer_two = StackingClassifier(estimators=layer_two_estimators, final_estimator=LogisticRegression())\n",
        "  \n",
        "  clf = StackingClassifier(estimators=layer_one_estimators, final_estimator=layer_two)\n",
        "  clf = clf.fit(Feature_train, y_train)\n",
        "  y_pred = clf.predict(Feature_test)\n",
        "  return y_pred\n",
        " \n",
        " \n",
        "#Importing Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import StackingClassifier\n",
        " \n",
        "#Read datasets X1 for Training dataset and y1 for testing dataset\n",
        "X1 = pd.read_csv(\"/content/drive/My Drive/KDDTrain+.csv\")\n",
        "#y1 = pd.read_csv(\"/content/drive/My Drive/KDDTest+.csv\")\n",
        "y1 = pd.read_csv(\"/content/drive/My Drive/attacks2.csv\")\n",
        "print(\"Any null values in Training dataset : \", X1.isnull().values.any())\n",
        "print(\"Any null values in Testing dataset : \", y1.isnull().values.any())\n",
        " \n",
        "print(\"Dimensions of Datasets before removing null valued rows\")\n",
        "print(\"Training Dataset : \",X1.shape)\n",
        "print(\"Testing Dataset : \",y1.shape)\n",
        " \n",
        "#Drop tuples with null values \n",
        "# X1 and y1 contains all 42 column\n",
        "X1.dropna(how='any',axis=0,inplace = True)\n",
        "y1.dropna(how='any',axis=0,inplace = True)\n",
        " \n",
        "print(\"Dimensions of Datasets after removing null valued rows\")\n",
        "print(\"Training Dataset : \",X1.shape)\n",
        "print(\"Testing Dataset : \",y1.shape)\n",
        " \n",
        "# Select only those 28 columns which KDD_Extractor extracts from network packet\n",
        "# These columns are for XGBOOST, Bagging and Adaboost (XBA)\n",
        "KDD_Extractor_features_28 = ['duration', 'protocol_type', 'flag', 'src_bytes', 'dst_bytes', 'land', \n",
        "                             'wrong_fragment', 'urgent', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n",
        "                             'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
        "                             'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                             'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "                             'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate','class']\n",
        " \n",
        "# Select only those 26 columns which KDD_Extractor extracts from network packet\n",
        "# These columns are for Random Forest, Extra Tree, Stacking (RES) \n",
        "KDD_Extractor_features_26 = ['duration', 'src_bytes', 'dst_bytes', 'land', \n",
        "                             'wrong_fragment', 'urgent', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', \n",
        "                             'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate',\n",
        "                             'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                             'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "                             'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate','class']\n",
        " \n",
        "# Select only KDD_Extractor columns\n",
        "# Use this for XGBoost, Bagging, Adaboost (XBA)\n",
        "'''\n",
        "X = pd.DataFrame(data = X1, columns = KDD_Extractor_features_28)\n",
        "y = pd.DataFrame(data = y1, columns = KDD_Extractor_features_28)\n",
        " \n",
        "'''\n",
        "# Uncomment this, if you are using any of the \"RES\" classifiers.\n",
        "# Select only KDD_Extractor columns\n",
        "# Use this for Random Forest, Extra Tree, Stacking (RES)\n",
        "X = pd.DataFrame(data = X1, columns = KDD_Extractor_features_26)\n",
        "y = pd.DataFrame(data = y1, columns = KDD_Extractor_features_26)\n",
        " \n",
        " \n",
        "# Split the dataset into features and labels\n",
        "X_train = X.iloc[:,:-1]\n",
        "y_train = X.iloc[:,-1]\n",
        "X_test = y.iloc[:,:-1]\n",
        "y_test = y.iloc[:,-1]\n",
        " \n",
        "print(\"X_train Shape : \",X_train.shape)\n",
        "print(\"X_test Shape : \",X_test.shape)\n",
        " \n",
        "'''\n",
        "Encode the categorical values to numerical values.\n",
        "And then drop the original attribute column containing categorical values.\n",
        " \n",
        "For Random Forest, Extra Tree, Stacking (RES), no need of this encoding,\n",
        "beacuse categorical columns doesn't exist in dataset and should be commented.\n",
        "'''\n",
        " \n",
        "'''\n",
        "#For training data\n",
        "Feature_train = X_train\n",
        "Feature_train = pd.concat([Feature_train,pd.get_dummies(X_train['protocol_type'])], axis=1)\n",
        "Feature_train = Feature_train.drop(['protocol_type'], axis = 1)\n",
        " \n",
        "Feature_train = pd.concat([Feature_train,pd.get_dummies(X_train['flag'])], axis=1)\n",
        "Feature_train = Feature_train.drop(['flag'], axis = 1)\n",
        " \n",
        " \n",
        "#For testing data\n",
        "Feature_test = X_test\n",
        "Feature_test = pd.concat([Feature_test,pd.get_dummies(X_test['protocol_type'])], axis=1)\n",
        "Feature_test = Feature_test.drop(['protocol_type'], axis = 1)\n",
        " \n",
        "Feature_test = pd.concat([Feature_test,pd.get_dummies(X_test['flag'])], axis=1)\n",
        "Feature_test = Feature_test.drop(['flag'], axis = 1)\n",
        "'''\n",
        " \n",
        "print(\"Feature_train Shape : \",Feature_train.shape)\n",
        " \n",
        "print(\"Feature_test Shape : \",Feature_test.shape)\n",
        " \n",
        "# Uncomment the classifier to be used\n",
        " \n",
        "# Gives Accuracy: 72.27077%\n",
        "#y_pred = xgboostClassifier(Feature_train, y_train, Feature_test)\n",
        " \n",
        "# Gives Accuracy: 71.84492%\n",
        "#y_pred = baggingClassifier_DT(Feature_train, y_train, Feature_test)\n",
        " \n",
        "# Gives Accuracy: 71.84492%\n",
        "#y_pred = adaboostClassifier(Feature_train, y_train, Feature_test)\n",
        "#print(y_test)\n",
        "y_pred = randomForestCLassifier(X_train, y_train, X_test)\n",
        " \n",
        "#y_pred = extraTreesClassifier(X_train, y_train, X_test)\n",
        " \n",
        "# Gives Accuracy: 71.41907%\n",
        "#y_pred = stackingClassifier(X_train, y_train, X_test)\n",
        " \n",
        "print(y_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Any null values in Training dataset :  True\n",
            "Any null values in Testing dataset :  False\n",
            "Dimensions of Datasets before removing null valued rows\n",
            "Training Dataset :  (125974, 42)\n",
            "Testing Dataset :  (19, 33)\n",
            "Dimensions of Datasets after removing null valued rows\n",
            "Training Dataset :  (125973, 42)\n",
            "Testing Dataset :  (19, 33)\n",
            "X_train Shape :  (125973, 25)\n",
            "X_test Shape :  (19, 25)\n",
            "Feature_train Shape :  (125973, 25)\n",
            "Feature_test Shape :  (19, 27)\n",
            "['normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
            " 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
            " 'normal' 'normal' 'normal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owop98LS_7A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzopqj0MkJCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}